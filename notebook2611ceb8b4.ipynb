{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6378201,"sourceType":"datasetVersion","datasetId":3675539}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nimport re\nimport pandas as pd\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nimport gensim\nfrom gensim.models import word2vec\nfrom gensim.models.word2vec import Word2Vec\nfrom keras.utils import pad_sequences\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\nimport numpy as np\nimport warnings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim.downloader as api\nprint(list(gensim.downloader.info()['models'].keys()))\nwv = api.load('word2vec-google-news-300')","metadata":{"id":"1ca64c02","outputId":"421165fa-f22d-4bf4-93a6-54722896f8c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(r\"/kaggle/input/review-data/review_data3.csv\")\n\ndf.head()","metadata":{"id":"fa9ebf50","outputId":"dc6566e4-6e4b-4110-8c90-ecf2662b078b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Unnamed: 0'], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(x = df['tokens'].apply(len))\nplt.xlabel('length_of_tokens')","metadata":{"id":"lajycYAIenhv","outputId":"c861e270-66c8-4d27-e2f0-5f0195f18dc4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokens_to_padded_embeddings_list(tokens_list, max_sequence_length = 500):\n    embeddings_list = []\n    for tokens in tokens_list:\n        embeddings = []\n        for token in tokens:\n            if token in wv.key_to_index:\n                embedding = wv[token]\n                embeddings.append(embedding)\n        embeddings_list.append(np.array(embeddings))\n\n    # Pad sequences to a common length\n    padded_embeddings_list = pad_sequences(embeddings_list, maxlen=max_sequence_length, padding='post', dtype='float32')\n    return padded_embeddings_list","metadata":{"id":"gvP8cjSybNzT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df['tokens']\ntrain_label = df['sentiment']\n\n","metadata":{"id":"f5d5f4c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(train, train_label, test_size = 0.15, random_state = 42, shuffle = True)","metadata":{"id":"a0aa86a4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = tokens_to_padded_embeddings_list(X_train.to_list())","metadata":{"id":"be9b6d4a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_valid = tokens_to_padded_embeddings_list(X_valid.to_list())","metadata":{"id":"9hDfCrYF3o7D","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_valid.shape","metadata":{"id":"IiGbAAfp3v8T","outputId":"cbdc3d80-7d40-4ddc-8ce1-4232b16e3a56","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"id":"ec732083","outputId":"9c5a5e17-a56f-4792-9f0f-da506695da5b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def create_bilstm_model():\n    model = Sequential([])\n\n    # Add Bidirectional LSTM layer\n    \n    \n    # Define the Bidirectional LSTM model\n    model = Sequential()\n\n    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(500, 300)))\n    model.add(layers.Dropout(0.2))\n\n    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True)))\n    model.add(layers.Dropout(0.2))\n\n    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True)))\n    model.add(layers.Dropout(0.2))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['f1'])\n\n    return model","metadata":{"id":"8f07d6c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_bilstm_model():\n    model = Sequential()\n\n    # Add Bidirectional LSTM layer\n    model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(500, 300)))\n    model.add(Dropout(0.3))\n    model.add(Bidirectional(LSTM(64)))\n    model.add(Dropout(0.3))\n\n    # Add output layer\n    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['f1'])\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = create_bilstm_model()\nmodel.summary()","metadata":{"id":"x2R2gwmJ2YxY","outputId":"bddc9486-9ca3-468b-ae2e-ee41ef2e639b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, Y_train,\n                    validation_data=(x_valid, Y_valid),\n                    batch_size=32, epochs=10)","metadata":{"id":"r69QpQZv2aLF","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}